{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1f8686-22d1-4a07-b86e-c524ea897654",
   "metadata": {},
   "source": [
    "# Building a ChatGPT-like Interface for Azure PostgreSQL Data\n",
    "\n",
    "This notebook demonstrates how to build a natural language interface to query Azure PostgreSQL data using Microsoft's **Semantic Kernel** and **Azure OpenAI**.  \n",
    "We will walk through:\n",
    "- Setting up environment variables\n",
    "- Connecting to Azure PostgreSQL\n",
    "- Initializing Semantic Kernel\n",
    "- Defining \"skills\" for SQL generation and answer formatting\n",
    "- Running queries end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d93605f-6d33-4f60-b0a3-9c4b84008855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Using cached psycopg2-2.9.10-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Using cached psycopg2-2.9.10-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.10\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0046b6-e696-46b7-bbf8-9d7726f6b406",
   "metadata": {},
   "source": [
    "**--- Load Environment Variables ---**\n",
    "\n",
    "- We use python-dotenv to load sensitive values (DB credentials, API keys) from a `.env` file.  \n",
    "- This ensures credentials are not hardcoded in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f60475a8-c4eb-4c77-94a8-bf11eacb14dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecfb824-41e7-4156-87e9-9de6352d36f8",
   "metadata": {},
   "source": [
    "**Database Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "709c430f-4796-4a7b-a493-a928ee379007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Connect to Azure PostgreSQL ---\n",
    "# psycopg2 is used for PostgreSQL connection and transaction management.\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=os.getenv(\"PGHOST\"),\n",
    "        dbname=os.getenv(\"PGDATABASE\"),\n",
    "        user=os.getenv(\"PGUSER\"),\n",
    "        password=os.getenv(\"PGPASSWORD\"),\n",
    "        port=os.getenv(\"PGPORT\"),\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Failed to connect to database: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "376138a8-8d9a-4b23-ab17-81a14c1f76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Kernel setup\n",
    "# --- Initialize Semantic Kernel ---\n",
    "# Semantic Kernel orchestrates AI workflows by combining:\n",
    "#  - Azure OpenAI (for natural language understanding)\n",
    "#  - Custom \"skills\" (for SQL generation & answer formatting)\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "try:\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=\"azure-openai\",\n",
    "            deployment_name=deployment_name,\n",
    "            endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize AzureChatCompletion: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f20ffa4-eac2-4095-83a8-21236faacf4b",
   "metadata": {},
   "source": [
    "**---Test 1 :  Define Semantic Kernel Skills to convert NL to SQL command ---**\n",
    "\n",
    "- Skills are modular functions defined via prompts or code.  \n",
    "- Here, we define:  \n",
    "  1. **GenerateSql** â†’ Converts natural language into SQL queries.  \n",
    "  2. **AnswerQuestion** â†’ Provides the SQL query or answers 'Not enough information'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a802e544-3b6b-41e8-ab3e-98f07f1ad0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "# --- Create SQL generator function ---\n",
    "sql_skill1 = kernel.add_function(\n",
    "    plugin_name=\"SqlSkill\",\n",
    "    function_name=\"GenerateSql\",\n",
    "    prompt=\"\"\"\n",
    "    You are a SQL generator.\n",
    "    Convert the user natural language question into a SQL query for the 'iris' table.\n",
    "    Return only the SQL query without explanation.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# --- Create Answering function ---\n",
    "answer_skill1 = kernel.add_function(\n",
    "    plugin_name=\"AnswerSkill\",\n",
    "    function_name=\"AnswerQuestion\",\n",
    "    prompt=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    Answer the user question based only on the provided database results.\n",
    "    If the answer cannot be determined, say \"Not enough information.\"\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f0319ab-2ee3-45e8-9b56-20a036c9f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    user_question = \"Show all iris records where species is setosa\"\n",
    "\n",
    "    # Generate SQL\n",
    "    sql_query = await sql_skill1.invoke(user_question)\n",
    "    print(\"Generated SQL:\", sql_query)\n",
    "\n",
    "    # Suppose SQL results are fetched\n",
    "    sql_results = [\n",
    "        {\"sepal_length\": 5.1, \"sepal_width\": 3.5, \"petal_length\": 1.4, \"petal_width\": 0.2, \"species\": \"setosa\"}\n",
    "    ]\n",
    "\n",
    "    # Get answer\n",
    "    answer = await answer_skill1.invoke(\n",
    "        f\"What is the average petal length?\",\n",
    "        context={\"results\": sql_results}\n",
    "    )\n",
    "    print(\"Answer:\", answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd3423a2-656b-40cd-8b16-fbe3a4044372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions.kernel_arguments import KernelArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c992622b-5ddc-4d0c-8fe9-b2a858e78577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL: SELECT * FROM iris WHERE species = 'setosa';\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Show all iris records where species is setosa\"\n",
    "\n",
    "# Generate SQL\n",
    "sql_query = await sql_skill1.invoke(\n",
    "    kernel,\n",
    "    KernelArguments(input=user_question)  # ðŸ‘ˆ wrap your input\n",
    ")\n",
    "\n",
    "print(\"Generated SQL:\", sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6bc26a-730e-48e2-b432-565978466d42",
   "metadata": {},
   "source": [
    "**---Test 2 : Converts NL Query->SQL-> Human readable answers ---**\n",
    "\n",
    "**--- Define Semantic Kernel Skills ---**\n",
    "- Skills are modular functions defined via prompts or code.  \n",
    "- Here, we define:  \n",
    "  1. **GenerateSql** â†’ Converts natural language into SQL queries.  \n",
    "  2. **AnswerQuestion** â†’ Formats raw query results into human-readable answers.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d56a6ca-bb9a-45b2-a0d7-0ea1951a2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SQL and Answer functions\n",
    "sql_skill = kernel.add_function(\n",
    "    plugin_name=\"SqlSkill\",\n",
    "    function_name=\"GenerateSql\",\n",
    "    prompt=\"\"\"\n",
    "    You are a SQL generator for a PostgreSQL database.\n",
    "    Convert the user natural language question into a SQL query for the 'iris' table with columns: sepal_length, sepal_width, petal_length, petal_width, species.\n",
    "    Return only the SQL query without explanation.\n",
    "    For average calculations, use ROUND(AVG(column)::numeric, 1) to handle double precision.\n",
    "    Examples:\n",
    "    - For \"average sepal length by species\": \"SELECT species, ROUND(AVG(sepal_length)::numeric, 1) AS avg_sepal_length FROM iris GROUP BY species;\"\n",
    "    - For \"list virginica flowers with petal width greater than 2.0\": \"SELECT sepal_length, sepal_width, petal_length, petal_width FROM iris WHERE species = 'virginica' AND petal_width > 2.0;\"\n",
    "    User Question: {{$input}}\n",
    "    \"\"\"\n",
    ")\n",
    "answer_skill = kernel.add_function(\n",
    "    plugin_name=\"AnswerSkill\",\n",
    "    function_name=\"AnswerQuestion\",\n",
    "    prompt=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    Answer the user question based only on the provided database results in JSON format.\n",
    "    If the results are empty, say \"No data available to answer the question.\"\n",
    "    For averages, use the format: \"The average sepal length is X for setosa, Y for versicolor, and Z for virginica.\"\n",
    "    For lists, use: \"There are N <species> flowers with <condition>: (x1, x2, x3, x4), ...\"\n",
    "    Numerical values should be rounded to one decimal place.\n",
    "    User Question: {{$input}}\n",
    "    SQL Results: {{$results}}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa366a93-2e92-4abe-96e8-fcae8825d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Orchestration Function ---\n",
    "# The ask_db function:\n",
    "#   1. Takes a natural language question\n",
    "#   2. Uses the SQL skill to generate a SQL query\n",
    "#   3. Executes the SQL query against Azure PostgreSQL\n",
    "#   4. Uses the Answer skill to turn results into a friendly response\n",
    "#   5. Returns the final answer to the user\n",
    "\n",
    "async def ask_db(question):\n",
    "    print(f\"Processing question: {question}\")\n",
    "    \n",
    "    # Generate SQL query\n",
    "    sql_skill = kernel.get_function(\"SqlSkill\", \"GenerateSql\")\n",
    "    try:\n",
    "        sql_query_result = await sql_skill.invoke(kernel, input=question)\n",
    "        sql_query = str(sql_query_result)\n",
    "        print(f\"Generated SQL: {sql_query}\")\n",
    "    except Exception as e:\n",
    "        return f\"Error generating SQL: {e}\"\n",
    "\n",
    "    # Execute SQL query\n",
    "    try:\n",
    "        cursor.execute(sql_query)\n",
    "        results = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        sql_results = [dict(zip(columns, row)) for row in results]\n",
    "        print(f\"SQL Results: {sql_results}\")\n",
    "        conn.commit()  \n",
    "    except psycopg2.Error as e:\n",
    "        conn.rollback() \n",
    "        return f\"Database error: {e}\"\n",
    "\n",
    "    # Answer the question\n",
    "    answer_skill = kernel.get_function(\"AnswerSkill\", \"AnswerQuestion\")\n",
    "    try:\n",
    "        answer = await answer_skill.invoke(\n",
    "            kernel,\n",
    "            input=question,\n",
    "            results=json.dumps(sql_results)\n",
    "        )\n",
    "        return str(answer)\n",
    "    except Exception as e:\n",
    "        return f\"Error generating answer: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a721e9f-0eac-41a5-90c2-b89516dcb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def run_queries():\n",
    "    print(await ask_db(\" what speicies does this belong to 6.8\t3.2\t5.9\t2.3? \"))\n",
    "    print(await ask_db(\"List all virginica flowers with petal width greater than 2.0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4c610-9023-4a8e-8383-f50749305dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question:  what speicies does this belong to 6.8\t3.2\t5.9\t2.3? \n",
      "Generated SQL: SELECT species FROM iris WHERE sepal_length = 6.8 AND sepal_width = 3.2 AND petal_length = 5.9 AND petal_width = 2.3;\n",
      "SQL Results: [{'species': 'virginica'}]\n",
      "The species of the flower with the characteristics mentioned is virginica.\n",
      "Processing question: List all virginica flowers with petal width greater than 2.0\n",
      "Generated SQL: SELECT sepal_length, sepal_width, petal_length, petal_width FROM iris WHERE species = 'virginica' AND petal_width > 2.0;\n",
      "SQL Results: [{'sepal_length': 6.3, 'sepal_width': 3.3, 'petal_length': 6.0, 'petal_width': 2.5}, {'sepal_length': 7.1, 'sepal_width': 3.0, 'petal_length': 5.9, 'petal_width': 2.1}, {'sepal_length': 6.5, 'sepal_width': 3.0, 'petal_length': 5.8, 'petal_width': 2.2}, {'sepal_length': 7.6, 'sepal_width': 3.0, 'petal_length': 6.6, 'petal_width': 2.1}, {'sepal_length': 7.2, 'sepal_width': 3.6, 'petal_length': 6.1, 'petal_width': 2.5}, {'sepal_length': 6.8, 'sepal_width': 3.0, 'petal_length': 5.5, 'petal_width': 2.1}, {'sepal_length': 5.8, 'sepal_width': 2.8, 'petal_length': 5.1, 'petal_width': 2.4}, {'sepal_length': 6.4, 'sepal_width': 3.2, 'petal_length': 5.3, 'petal_width': 2.3}, {'sepal_length': 7.7, 'sepal_width': 3.8, 'petal_length': 6.7, 'petal_width': 2.2}, {'sepal_length': 7.7, 'sepal_width': 2.6, 'petal_length': 6.9, 'petal_width': 2.3}, {'sepal_length': 6.9, 'sepal_width': 3.2, 'petal_length': 5.7, 'petal_width': 2.3}, {'sepal_length': 6.7, 'sepal_width': 3.3, 'petal_length': 5.7, 'petal_width': 2.1}, {'sepal_length': 6.4, 'sepal_width': 2.8, 'petal_length': 5.6, 'petal_width': 2.1}, {'sepal_length': 6.4, 'sepal_width': 2.8, 'petal_length': 5.6, 'petal_width': 2.2}, {'sepal_length': 7.7, 'sepal_width': 3.0, 'petal_length': 6.1, 'petal_width': 2.3}, {'sepal_length': 6.3, 'sepal_width': 3.4, 'petal_length': 5.6, 'petal_width': 2.4}, {'sepal_length': 6.9, 'sepal_width': 3.1, 'petal_length': 5.4, 'petal_width': 2.1}, {'sepal_length': 6.7, 'sepal_width': 3.1, 'petal_length': 5.6, 'petal_width': 2.4}, {'sepal_length': 6.9, 'sepal_width': 3.1, 'petal_length': 5.1, 'petal_width': 2.3}, {'sepal_length': 6.8, 'sepal_width': 3.2, 'petal_length': 5.9, 'petal_width': 2.3}, {'sepal_length': 6.7, 'sepal_width': 3.3, 'petal_length': 5.7, 'petal_width': 2.5}, {'sepal_length': 6.7, 'sepal_width': 3.0, 'petal_length': 5.2, 'petal_width': 2.3}, {'sepal_length': 6.2, 'sepal_width': 3.4, 'petal_length': 5.4, 'petal_width': 2.3}]\n",
      "There are 23 virginica flowers with petal width greater than 2.0: (6.3, 7.1, 6.5, 7.6, 7.2, 6.8, 5.8, 6.4, 7.7, 7.7, 6.9, 6.7, 6.4, 6.4, 7.7, 6.3, 6.9, 6.7, 6.9, 6.8, 6.7, 6.7, 6.2).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "await run_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c476b5-04be-4428-8325-0c6297074d92",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We successfully built a ChatGPT-like interface to query Azure PostgreSQL data.  \n",
    "By leveraging Semantic Kernel, we combined:\n",
    "- LLM-based natural language understanding\n",
    "- SQL query generation\n",
    "- Database connectivity\n",
    "- Human-readable responses  \n",
    "\n",
    "This pipeline can be extended to other datasets and domains, enabling Natural Language Querying (NLQ) for business users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a1915-724c-48ee-b336-a3c622b71e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
